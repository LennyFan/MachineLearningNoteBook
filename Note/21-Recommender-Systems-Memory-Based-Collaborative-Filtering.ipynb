{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems\n",
    "\n",
    "        Book: Recomender Systems by Jannach and Zanker\n",
    "        \n",
    "        > Linear Algebra\n",
    "***\n",
    "        \n",
    "## Two Most Common Type of Recommender System\n",
    "\n",
    "- ** Content-Based **\n",
    "\n",
    "    Focusing on the attributes of the items and recommending ** based on the similarity between items ** ( ex. based on similar items )\n",
    "\n",
    "\n",
    "- ** Collaborative Filtering (CF) **\n",
    "\n",
    "    ** Based on the knowledge of users' attitude to items** , which means it uses the \"wisdom of crowd\" to recommend the items ( ex. based on others shopping experience )\n",
    "    \n",
    "    > can be divided into ** Memory-Based Collaborative Filtering** and ** Model-Based Colaborative filtering**.\n",
    "    \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explicit feedback model/ implicit feedback model\n",
    "\n",
    "Most recommendation models consist of building a user-by-item matrix (pivot table). If the entries value is the **numerical ratings that users give items, then this is called an explicit feedback model**. Alternatively, **one may include implicit feedback which are actions by a user that signify a positive or negative preference** for a given item (such as viewing the item online). \n",
    "\n",
    "> These two scenarios often must be treated differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id              title\n",
       "0        1   Toy Story (1995)\n",
       "1        2   GoldenEye (1995)\n",
       "2        3  Four Rooms (1995)\n",
       "3        4  Get Shorty (1995)\n",
       "4        5     Copycat (1995)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('u.data', sep='\\t', names=column_names)\n",
    "movie_titles = pd.read_csv(\"Movie_Id_Titles\")\n",
    "movie_titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>880473582</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>891271545</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>888552084</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>879362124</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp             title\n",
       "0        0       50       5  881250949  Star Wars (1977)\n",
       "1      290       50       5  880473582  Star Wars (1977)\n",
       "2       79       50       4  891271545  Star Wars (1977)\n",
       "3        2       50       5  888552084  Star Wars (1977)\n",
       "4        8       50       5  879362124  Star Wars (1977)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df,movie_titles,on='item_id')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. of Users: 944\n",
      "Num of Movies: 1682\n"
     ]
    }
   ],
   "source": [
    "n_users = df.user_id.nunique()\n",
    "n_items = df.item_id.nunique()\n",
    "\n",
    "print('Num. of Users: '+ str(n_users))\n",
    "print('Num of Movies: '+str(n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Preprocess/ Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 1664)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.item_id.nunique(), df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Body Snatchers (1993)             2\n",
       "Butcher Boy, The (1998)           2\n",
       "Chairman of the Board (1998)      2\n",
       "Chasing Amy (1997)                2\n",
       "Deceiver (1997)                   2\n",
       "Designated Mourner, The (1997)    2\n",
       "Desperate Measures (1998)         2\n",
       "Fly Away Home (1996)              2\n",
       "Hugo Pool (1997)                  2\n",
       "Hurricane Streets (1998)          2\n",
       "Ice Storm, The (1997)             2\n",
       "Kull the Conqueror (1997)         2\n",
       "Money Talks (1997)                2\n",
       "Nightwatch (1997)                 2\n",
       "Sliding Doors (1998)              2\n",
       "Substance of Fire, The (1996)     2\n",
       "That Darn Cat! (1997)             2\n",
       "Ulee's Gold (1997)                2\n",
       "Name: item_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_unique = df.groupby(\"title\").item_id.nunique()\n",
    "check_unique[check_unique > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    id is not unique, we would like to clean id...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_unique = pd.DataFrame(check_unique[check_unique > 1])\n",
    "#check_unique.join(df.set_index(\"title\"),how = \"left\")\n",
    "check_unique[\"count\"] = check_unique\n",
    "check_unique.drop(\"item_id\",inplace=True,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Body Snatchers (1993)</th>\n",
       "      <th>573</th>\n",
       "      <td>33.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>573.0</td>\n",
       "      <td>573.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>36.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>670.0</td>\n",
       "      <td>670.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Butcher Boy, The (1998)</th>\n",
       "      <th>1645</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1645.0</td>\n",
       "      <td>1645.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>1650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Chairman of the Board (1998)</th>\n",
       "      <th>1234</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>1234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>1654.0</td>\n",
       "      <td>1654.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Chasing Amy (1997)</th>\n",
       "      <th>246</th>\n",
       "      <td>124.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>246.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>255.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Deceiver (1997)</th>\n",
       "      <th>309</th>\n",
       "      <td>28.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>1606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Designated Mourner, The (1997)</th>\n",
       "      <th>1256</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>1256.0</td>\n",
       "      <td>1256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>1257.0</td>\n",
       "      <td>1257.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Desperate Measures (1998)</th>\n",
       "      <th>329</th>\n",
       "      <td>45.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>27.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>348.0</td>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Fly Away Home (1996)</th>\n",
       "      <th>304</th>\n",
       "      <td>149.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>31.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Hugo Pool (1997)</th>\n",
       "      <th>1175</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>1175.0</td>\n",
       "      <td>1175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>1617.0</td>\n",
       "      <td>1617.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Hurricane Streets (1998)</th>\n",
       "      <th>1395</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>1395.0</td>\n",
       "      <td>1395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>1607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Ice Storm, The (1997)</th>\n",
       "      <th>305</th>\n",
       "      <td>87.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>21.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>865.0</td>\n",
       "      <td>865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Kull the Conqueror (1997)</th>\n",
       "      <th>266</th>\n",
       "      <td>35.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>34.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Money Talks (1997)</th>\n",
       "      <th>876</th>\n",
       "      <td>47.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>45.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>881.0</td>\n",
       "      <td>881.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Nightwatch (1997)</th>\n",
       "      <th>1477</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>1477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>1625.0</td>\n",
       "      <td>1625.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Sliding Doors (1998)</th>\n",
       "      <th>1429</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>1429.0</td>\n",
       "      <td>1429.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>1680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Substance of Fire, The (1996)</th>\n",
       "      <th>711</th>\n",
       "      <td>1.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>711.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">That Darn Cat! (1997)</th>\n",
       "      <th>878</th>\n",
       "      <td>33.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Ulee's Gold (1997)</th>\n",
       "      <th>297</th>\n",
       "      <td>50.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>134.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>303.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        count    mean  std     min     25%  \\\n",
       "title                          item_id                                       \n",
       "Body Snatchers (1993)          573       33.0   573.0  0.0   573.0   573.0   \n",
       "                               670       36.0   670.0  0.0   670.0   670.0   \n",
       "Butcher Boy, The (1998)        1645       1.0  1645.0  NaN  1645.0  1645.0   \n",
       "                               1650       1.0  1650.0  NaN  1650.0  1650.0   \n",
       "Chairman of the Board (1998)   1234       8.0  1234.0  0.0  1234.0  1234.0   \n",
       "                               1654       1.0  1654.0  NaN  1654.0  1654.0   \n",
       "Chasing Amy (1997)             246      124.0   246.0  0.0   246.0   246.0   \n",
       "                               268      255.0   268.0  0.0   268.0   268.0   \n",
       "Deceiver (1997)                309       28.0   309.0  0.0   309.0   309.0   \n",
       "                               1606       1.0  1606.0  NaN  1606.0  1606.0   \n",
       "Designated Mourner, The (1997) 1256       3.0  1256.0  0.0  1256.0  1256.0   \n",
       "                               1257       4.0  1257.0  0.0  1257.0  1257.0   \n",
       "Desperate Measures (1998)      329       45.0   329.0  0.0   329.0   329.0   \n",
       "                               348       27.0   348.0  0.0   348.0   348.0   \n",
       "Fly Away Home (1996)           304      149.0   304.0  0.0   304.0   304.0   \n",
       "                               500       31.0   500.0  0.0   500.0   500.0   \n",
       "Hugo Pool (1997)               1175       5.0  1175.0  0.0  1175.0  1175.0   \n",
       "                               1617       2.0  1617.0  0.0  1617.0  1617.0   \n",
       "Hurricane Streets (1998)       1395       6.0  1395.0  0.0  1395.0  1395.0   \n",
       "                               1607       3.0  1607.0  0.0  1607.0  1607.0   \n",
       "Ice Storm, The (1997)          305       87.0   305.0  0.0   305.0   305.0   \n",
       "                               865       21.0   865.0  0.0   865.0   865.0   \n",
       "Kull the Conqueror (1997)      266       35.0   266.0  0.0   266.0   266.0   \n",
       "                               680       34.0   680.0  0.0   680.0   680.0   \n",
       "Money Talks (1997)             876       47.0   876.0  0.0   876.0   876.0   \n",
       "                               881       45.0   881.0  0.0   881.0   881.0   \n",
       "Nightwatch (1997)              1477       2.0  1477.0  0.0  1477.0  1477.0   \n",
       "                               1625       1.0  1625.0  NaN  1625.0  1625.0   \n",
       "Sliding Doors (1998)           1429       4.0  1429.0  0.0  1429.0  1429.0   \n",
       "                               1680       1.0  1680.0  NaN  1680.0  1680.0   \n",
       "Substance of Fire, The (1996)  711        1.0   711.0  NaN   711.0   711.0   \n",
       "                               1658       3.0  1658.0  0.0  1658.0  1658.0   \n",
       "That Darn Cat! (1997)          878       33.0   878.0  0.0   878.0   878.0   \n",
       "                               1003       8.0  1003.0  0.0  1003.0  1003.0   \n",
       "Ulee's Gold (1997)             297       50.0   297.0  0.0   297.0   297.0   \n",
       "                               303      134.0   303.0  0.0   303.0   303.0   \n",
       "\n",
       "                                           50%     75%     max  \n",
       "title                          item_id                          \n",
       "Body Snatchers (1993)          573       573.0   573.0   573.0  \n",
       "                               670       670.0   670.0   670.0  \n",
       "Butcher Boy, The (1998)        1645     1645.0  1645.0  1645.0  \n",
       "                               1650     1650.0  1650.0  1650.0  \n",
       "Chairman of the Board (1998)   1234     1234.0  1234.0  1234.0  \n",
       "                               1654     1654.0  1654.0  1654.0  \n",
       "Chasing Amy (1997)             246       246.0   246.0   246.0  \n",
       "                               268       268.0   268.0   268.0  \n",
       "Deceiver (1997)                309       309.0   309.0   309.0  \n",
       "                               1606     1606.0  1606.0  1606.0  \n",
       "Designated Mourner, The (1997) 1256     1256.0  1256.0  1256.0  \n",
       "                               1257     1257.0  1257.0  1257.0  \n",
       "Desperate Measures (1998)      329       329.0   329.0   329.0  \n",
       "                               348       348.0   348.0   348.0  \n",
       "Fly Away Home (1996)           304       304.0   304.0   304.0  \n",
       "                               500       500.0   500.0   500.0  \n",
       "Hugo Pool (1997)               1175     1175.0  1175.0  1175.0  \n",
       "                               1617     1617.0  1617.0  1617.0  \n",
       "Hurricane Streets (1998)       1395     1395.0  1395.0  1395.0  \n",
       "                               1607     1607.0  1607.0  1607.0  \n",
       "Ice Storm, The (1997)          305       305.0   305.0   305.0  \n",
       "                               865       865.0   865.0   865.0  \n",
       "Kull the Conqueror (1997)      266       266.0   266.0   266.0  \n",
       "                               680       680.0   680.0   680.0  \n",
       "Money Talks (1997)             876       876.0   876.0   876.0  \n",
       "                               881       881.0   881.0   881.0  \n",
       "Nightwatch (1997)              1477     1477.0  1477.0  1477.0  \n",
       "                               1625     1625.0  1625.0  1625.0  \n",
       "Sliding Doors (1998)           1429     1429.0  1429.0  1429.0  \n",
       "                               1680     1680.0  1680.0  1680.0  \n",
       "Substance of Fire, The (1996)  711       711.0   711.0   711.0  \n",
       "                               1658     1658.0  1658.0  1658.0  \n",
       "That Darn Cat! (1997)          878       878.0   878.0   878.0  \n",
       "                               1003     1003.0  1003.0  1003.0  \n",
       "Ulee's Gold (1997)             297       297.0   297.0   297.0  \n",
       "                               303       303.0   303.0   303.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_unique.join(df.set_index(\"title\").item_id,how = \"left\").groupby([\"title\",\"item_id\"]).item_id.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       above movies all has two id lol..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reformat id\n",
    "new_movie_index = dict((y, x) for x, y in zip(range(df.title.nunique()),df.title.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1664, 1664)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.item_id = df.title.map(new_movie_index)\n",
    "df.item_id.nunique(), df.title.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1654</th>\n",
       "      <th>1655</th>\n",
       "      <th>1656</th>\n",
       "      <th>1657</th>\n",
       "      <th>1658</th>\n",
       "      <th>1659</th>\n",
       "      <th>1660</th>\n",
       "      <th>1661</th>\n",
       "      <th>1662</th>\n",
       "      <th>1663</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 1664 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  0     1     2     3     4     5     6     7     8     9     ...   \\\n",
       "user_id                                                              ...    \n",
       "0           5     5     1     0     0     0     0     0     0     0  ...    \n",
       "1           5     5     4     5     0     0     4     0     0     4  ...    \n",
       "\n",
       "item_id  1654  1655  1656  1657  1658  1659  1660  1661  1662  1663  \n",
       "user_id                                                              \n",
       "0           0     0     0     0     0     0     0     0     0     0  \n",
       "1           0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[2 rows x 1664 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first get pivot table\n",
    "user_item_matrix = pd.pivot_table(df,\"rating\",\"user_id\",\"item_id\",fill_value=0)\n",
    "user_item_matrix.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- ## Sparsity \n",
    "\n",
    "    This means that the percentage of the user-item-matrix have a real value\n",
    "\n",
    "$$ {\\#\\mbox{ of valid entry } \\over \\# \\mbox{ of total entry } } \\times 100 \\%$$\n",
    "\n",
    "    One thing to note is that if the sparsity of the matrix is below 1% (rule of thumb), then the dataset might be too sparse to perform any sort of modeling.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.34676499348 %\n"
     ]
    }
   ],
   "source": [
    "print 100.0*sum(user_item_matrix[user_item_matrix != 0].count())/user_item_matrix.shape[0]/user_item_matrix.shape[1] ,\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    944.000000\n",
       "mean     105.610169\n",
       "std      100.622846\n",
       "min        3.000000\n",
       "25%       33.000000\n",
       "50%       64.000000\n",
       "75%      147.250000\n",
       "max      736.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix[user_item_matrix != 0].count(axis = 1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbwAAAD8CAYAAAAMnxEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZKaYOBJkppg4EmSmvC/wS09CHhZ2f4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1133280d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "user_item_matrix[user_item_matrix != 0].count(axis = 1).plot(kind = \"hist\",bins = 300)\n",
    "plt.xlim(0,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Notice that some people rated less than 10 movies, therefore we would like to remove this data which is hard for us to consider their opinion as \"useful\". In this case we would like to remomve the user in our model who rated less than 10 movies. Thus, every user has rated at least 19 movies (show below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print list(user_item_matrix[user_item_matrix[user_item_matrix != 0].count(axis = 1) <= 10].index)\n",
    "user_item_matrix = user_item_matrix[user_item_matrix[user_item_matrix != 0].count(axis = 1) > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[df.user_id != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    943.000000\n",
       "mean     105.718982\n",
       "std      100.620656\n",
       "min       19.000000\n",
       "25%       33.000000\n",
       "50%       64.000000\n",
       "75%      147.500000\n",
       "max      736.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix[user_item_matrix != 0].count(axis = 1).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Train Test Split\n",
    "    \n",
    "    Note that in this case, we have no specific predicted/responsed variables. What we want to do is using some existing entries to predict other none entries based on a specific user or item. More appropriately, we would like to randomly split our data into training and test sets by removing some exsiting ratings from the training set and placing them in the test set. \n",
    "    \n",
    "    There are two ways to do this.\n",
    "    >1.\n",
    "    \n",
    "    > we can just segement the **original data frame** into two sets of data, basically we remove some rate\n",
    "    \n",
    "    >         sklearn.cross_validation import train_test_split\n",
    "    > 2.\n",
    "    \n",
    "    > The first approach might remove all the rate from single person which is what we want to avoiding, since it will have no attiribute for us to recommand other movies for him cause we don't have any his data in training model. More appropriately, we would like to removing some ratings **per user** from the training set and placing them in the test set.\n",
    "    \n",
    "    > In this case, it's reasonble for us to removing 9 ratings per user from the training set since each user has rated at least 19 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#1.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data1, test_data1 = train_test_split(df, test_size=0.25)\n",
    "\n",
    "#2.\n",
    "def train_test_split(ratings):\n",
    "    test = pd.DataFrame(np.zeros(ratings.shape), index = ratings.index, columns = ratings.columns)\n",
    "    train = ratings.copy()\n",
    "    for i in range(len(ratings.index)):\n",
    "        \n",
    "        \n",
    "        test_ratings = np.random.choice(\n",
    "                        ratings.iloc[i].nonzero()[0], # Return the 2D-indices of the elements that are non-zero\n",
    "                        size=9, \n",
    "                        replace=False) # sample without replacement\n",
    "        \n",
    "        train.iloc[i,test_ratings] = 0\n",
    "        test.iloc[i,test_ratings] = ratings.iloc[i,test_ratings]\n",
    "        \n",
    "    # Test and training are truly disjoint\n",
    "    assert(np.all((train * test) == 0)) \n",
    "    return train, test\n",
    "\n",
    "train_data2, test_data2 =train_test_split(user_item_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory-Based Collaborative Filtering\n",
    "\n",
    "Memory-Based Collaborative Filtering approaches can be divided into two main sections: **user-item filtering** and **item-item filtering**. \n",
    "\n",
    "A *user-item filtering* will take a particular user, find users that are similar to that user based on similarity of ratings, and recommend items that those similar users liked. \n",
    "\n",
    "In contrast, *item-item filtering* will take an item, find users who liked that item, and find other items that those users or similar users also liked. It takes items and outputs other items as recommendations. \n",
    "\n",
    "* *Item-Item Collaborative Filtering*: â€œUsers who liked this item also liked â€¦â€\n",
    "* *User-Item Collaborative Filtering*: â€œUsers who are similar to you also liked â€¦â€\n",
    "\n",
    "***\n",
    "\n",
    "- ## Compute Distance Matric / Calculate Similarity\n",
    "\n",
    "    **  cosine similarity **\n",
    "    \n",
    "    > *user-item similarity:*\n",
    "    \n",
    "    > for any pair of users vector $u_k$ and the user vector $u_a$ \n",
    "    \n",
    "    <img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?s_u^{cos}(u_k,u_a)=\\frac{u_k&space;\\cdot&space;u_a&space;}{&space;\\left&space;\\|&space;u_k&space;\\right&space;\\|&space;\\left&space;\\|&space;u_a&space;\\right&space;\\|&space;}&space;=\\frac{\\sum&space;x_{k,m}x_{a,m}}{\\sqrt{\\sum&space;x_{k,m}^2\\sum&space;x_{a,m}^2}}\"/>\n",
    "    \n",
    "    > *item-item similarity:*\n",
    "    \n",
    "    > for any pair of item vector $i_m$ and the item vector $i_b$ \n",
    "    \n",
    "    <img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?s_u^{cos}(i_m,i_b)=\\frac{i_m&space;\\cdot&space;i_b&space;}{&space;\\left&space;\\|&space;i_m&space;\\right&space;\\|&space;\\left&space;\\|&space;i_b&space;\\right&space;\\|&space;}&space;=\\frac{\\sum&space;x_{a,m}x_{a,b}}{\\sqrt{\\sum&space;x_{a,m}^2\\sum&space;x_{a,b}^2}}\n",
    "\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>880473582</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>891271545</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>888552084</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>879362124</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>274</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>878944679</td>\n",
       "      <td>Star Wars (1977)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp             title\n",
       "1      290        0       5  880473582  Star Wars (1977)\n",
       "2       79        0       4  891271545  Star Wars (1977)\n",
       "3        2        0       5  888552084  Star Wars (1977)\n",
       "4        8        0       5  879362124  Star Wars (1977)\n",
       "5      274        0       5  878944679  Star Wars (1977)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df.user_id.unique()) == range(1,944)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_data1, test_data1\n",
    "#Create two user-item matrices, one for training and another for testing\n",
    "# numpy version\n",
    "train_data_matrix1 = np.zeros((df.user_id.nunique(), df.item_id.nunique()))\n",
    "for line in train_data1.itertuples():\n",
    "    train_data_matrix1[line[1]-1, line[2]-1] = line[3]  \n",
    "\n",
    "test_data_matrix1 = np.zeros((df.user_id.nunique(), df.item_id.nunique()))\n",
    "for line in test_data1.itertuples():\n",
    "    test_data_matrix1[line[1]-1, line[2]-1] = line[3]\n",
    "    \n",
    "# pandas version\n",
    "# doesn't work!!!!!!!!!!!!!!!!!!! since some movie might be removed\n",
    "train_data_matrix_df = pd.pivot_table(train_data1,\"rating\",\"user_id\",\"item_id\",fill_value=0)\n",
    "test_data_matrix_df = pd.pivot_table(test_data1,\"rating\",\"user_id\",\"item_id\",fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        \n",
    ">    **Note: Using pairwise_distance migth be helpful to avoid divide by zero when predicting the value**\n",
    "        \n",
    "[pairwise_distances](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.pairwise_distances.html) function from sklearn to calculate the cosine similarity. Note, the output will range from 0 to 1 since the ratings are all positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## same as below\n",
    "def df_similarity(ratings, kind='user', epsilon=1e-9):\n",
    "    # epsilon -> small number for handling dived-by-zero errors\n",
    "    if kind == 'user':\n",
    "        sim = ratings.dot(ratings.T) + epsilon\n",
    "    elif kind == 'item':\n",
    "        sim = ratings.T.dot(ratings) + epsilon\n",
    "    norms = np.array(np.sqrt(np.diagonal(sim)))\n",
    "    \n",
    "    return (sim.divide(norms,axis = 1).divide(norms,axis = 0))\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "user_similarity_distance1 = pairwise_distances(train_data_matrix1, metric='cosine')\n",
    "item_similarity_distance1 = pairwise_distances(train_data_matrix1.T, metric='cosine')\n",
    "user_similarity1 = cosine_similarity(train_data_matrix1)\n",
    "item_similarity1 = cosine_similarity(train_data_matrix1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "user_similarity2 = df_similarity(train_data2, kind='user')\n",
    "item_similarity2 = df_similarity(train_data2, kind='item')\n",
    "user_similarity_distance2 = pairwise_distances(train_data2, metric='cosine')\n",
    "item_similarity_distance2 = pairwise_distances(train_data2.T, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id         1         2         3\n",
      "user_id                              \n",
      "1        1.000000  0.151966  0.028114\n",
      "2        0.151966  1.000000  0.071804\n",
      "3        0.028114  0.071804  1.000000\n",
      "\n",
      "\n",
      "[[ 1.          0.15196642  0.02811438]\n",
      " [ 0.15196642  1.          0.07180396]\n",
      " [ 0.02811438  0.07180396  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print user_similarity2.iloc[:3,:3]\n",
    "print \"\\n\"\n",
    "print cosine_similarity(train_data2)[:3,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mbox{Similarity Distance Matric} = 1 - \\mbox{Similarity Matric }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id   1    2    3    4    5    6    7    8    9    10\n",
      "user_id                                                  \n",
      "1       -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "2       -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "3       -0.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "4       -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "5       -0.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "6       -0.0 -0.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0\n",
      "7       -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "8       -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n",
      "9       -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  0.0 -0.0\n",
      "10      -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n"
     ]
    }
   ],
   "source": [
    "# actually are same\n",
    "print ((1-user_similarity2) - user_similarity_distance2).round(2).iloc[:10,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- ## Prddict\n",
    "\n",
    "    With our similarity matrix in hand, we can now predict the ratings that were not included with the data. The idea is very simple, for item *m*, we use the similarity between item *m* and any other items denoted by *b* as weights that are multiplied by the ratings of user *b*. Thus, we will get the expected total rating score of item *m* from user *k*\n",
    "    \n",
    "    $$ \\hat{X}_{k,m} = \\sum_{i_b} sim_i(i_m,i_b) \\; X_{k,b} $$\n",
    "    \n",
    "    We must also normalize by the number by total weights, if not we can get very large number if we have a very\n",
    "    large data set\n",
    "    \n",
    "    Therefore the prediction rating of each entry will be\n",
    "    \n",
    "    <img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?\\hat{x}_{k,m}&space;=&space;\\frac{\\sum\\limits_{i_b}&space;sim_i(i_m,&space;i_b)&space;(x_{k,b})&space;}{\\sum\\limits_{i_b}|sim_i(i_m,&space;i_b)|}\"/>\n",
    "    \n",
    "    \n",
    "    \n",
    "   ** It turns out that we might like to do some correction for user-item silimarity model **. The idea here is that some every users rates the movies differently (some might always rates higher. For example, a user *k* gives 4 stars to his favourite movies while a user *a* gives 5 stars to her favourite movies). \n",
    "   \n",
    "   ** The relative difference in the ratings that these users give is more important than the absolute values. ** Therefore, we can correct the prediction by the user's average rating. Which will be the equation below\n",
    "   \n",
    "   ### which also known as Bias-subtracted Collaborative Filtering\n",
    "   \n",
    "   \n",
    "   <img class=\"aligncenter size-thumbnail img-responsive\" src=\"https://latex.codecogs.com/gif.latex?\\hat{x}_{k,m}&space;=&space;\\bar{x}_{k}&space;&plus;&space;\\frac{\\sum\\limits_{u_a}&space;sim_u(u_k,&space;u_a)&space;(x_{a,m}&space;-&space;\\bar{x_{u_a}})}{\\sum\\limits_{u_a}|sim_u(u_k,&space;u_a)|}\"/>\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_correc(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        #You use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis]) \n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])     \n",
    "    return pred\n",
    "\n",
    "def predict_nocorrec(ratings, similarity, kind='user'):\n",
    "    if kind == 'user':\n",
    "        return similarity.dot(ratings) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif kind == 'item':\n",
    "        return ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_prediction_c1 = predict_correc(train_data_matrix1, 1- item_similarity_distance1, type='item')\n",
    "user_prediction_c1 = predict_correc(train_data_matrix1, 1- user_similarity_distance1, type='user')\n",
    "\n",
    "item_prediction_nc1 = predict_nocorrec(train_data_matrix1, 1- item_similarity_distance1, kind='item')\n",
    "user_prediction_nc1 = predict_nocorrec(train_data_matrix1, 1- user_similarity_distance1, kind='user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_prediction_c2 = predict_correc(np.array(train_data2), np.array(item_similarity2), type='item')\n",
    "user_prediction_c2 = predict_correc(np.array(train_data2), np.array(user_similarity2), type='user')\n",
    "\n",
    "item_prediction_nc2 = predict_nocorrec(np.array(train_data2), np.array(item_similarity2), kind='item')\n",
    "user_prediction_nc2 = predict_nocorrec(np.array(train_data2), np.array(user_similarity2), kind='user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "- ## Evaluate\n",
    "\n",
    "       from sklearn.metrics import mean_squared_error\n",
    "       \n",
    "    There are many evaluation metrics but one of the most popular metric used to evaluate accuracy of predicted ratings is **Mean Squared Error (MSE)** or **Root Mean Squared Error (RMSE)**.\n",
    "    \n",
    "    <img src=\"https://latex.codecogs.com/gif.latex?RMSE&space;=\\sqrt{\\frac{1}{N}&space;\\sum&space;(x_i&space;-\\hat{x_i})^2}\" title=\"RMSE =\\sqrt{\\frac{1}{N} \\sum (x_i -\\hat{x_i})^2}\" />\n",
    "\n",
    "    >  Note: we only want to consider predicted ratings that are in the **test dataset**, thus we should filter out all other elements in the prediction matrix with \n",
    "    \n",
    "        prediction[actual.nonzero()].flatten()\n",
    "        \n",
    "        df.nonzero() --->  Return the indices sets of the elements that are non-zero\n",
    "        \n",
    "        flatten() --->  Return a copy of the array collapsed into one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  4.,  4., ...,  5.,  2.,  3.])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_matrix1[test_data_matrix1.nonzero()].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def mse(prediction, actual):\n",
    "    prediction = prediction[actual.nonzero()].flatten() \n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return mean_squared_error(actual, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with correction for user-item\n",
      "User-based CF MSE: 8.47136899034\n",
      "Item-based CF MSE: 9.71654396372\n",
      "\n",
      "\n",
      "without correction for user-item\n",
      "User-based CF MSE: 8.96642188179\n",
      "Item-based CF MSE: 9.71654396372\n"
     ]
    }
   ],
   "source": [
    "print \"with correction for user-item\"\n",
    "print('User-based CF MSE: ' + str(mse(user_prediction_c1, test_data_matrix)))\n",
    "print('Item-based CF MSE: ' + str(mse(item_prediction_c1, test_data_matrix)))\n",
    "print \"\\n\"\n",
    "print \"without correction for user-item\"\n",
    "print('User-based CF MSE: ' + str(mse(user_prediction_nc1, test_data_matrix)))\n",
    "print('Item-based CF MSE: ' + str(mse(item_prediction_nc1, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with correction for user-item\n",
      "User-based CF MSE: 8.61736234396\n",
      "Item-based CF MSE: 11.4817399261\n",
      "\n",
      "\n",
      "without correction for user-item\n",
      "User-based CF MSE: 8.34417890795\n",
      "Item-based CF MSE: 11.4817399261\n"
     ]
    }
   ],
   "source": [
    "print \"with correction for user-item\"\n",
    "print('User-based CF MSE: ' + str(mse(user_prediction_c2, np.array(test_data2))))\n",
    "print('Item-based CF MSE: ' + str(mse(item_prediction_c2, np.array(test_data2))))\n",
    "print \"\\n\"\n",
    "print \"without correction for user-item\"\n",
    "print('User-based CF MSE: ' + str(mse(user_prediction_nc2, np.array(test_data2))))\n",
    "print('Item-based CF MSE: ' + str(mse(item_prediction_nc2, np.array(test_data2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Conclution:\n",
    "\n",
    "   After several testing, ** using the second way to split the data provide better prediction on user-based CF but the first way provide the better prediction on Item-based CF**. However, it is still not clear which model should we prefer. We should use **cross validation** to choose the best performance.\n",
    "   \n",
    "   It is interesting to see that actually the prediction with correction does not always performe better than the prediction without correction. It is also not cleat that which train split data will provide better result. More appropriately, we should use **cross validation** to choose the best performance.\n",
    "   \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Improvement: Top-K Collaborative Filtering\n",
    "\n",
    "    We can attempt to improve our prediction MSE by only considering the top *k* users who are most similar to the input user (or, similarly, the top *k* items). That is, when we calculate the sums over users/items, we only sum over the top *k* most similar users/items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_nocorrec_topk(ratings, similarity, kind='user', k=40):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    if kind == 'user':\n",
    "        for i in xrange(ratings.shape[0]):\n",
    "            top_k_users = [np.argsort(similarity[:,i])[:-k-1:-1]]\n",
    "            for j in xrange(ratings.shape[1]):\n",
    "                pred[i, j] = similarity[i, :][top_k_users].dot(ratings[:, j][top_k_users]) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[i, :][top_k_users]))\n",
    "    if kind == 'item':\n",
    "        for j in xrange(ratings.shape[1]):\n",
    "            top_k_items = [np.argsort(similarity[:,j])[:-k-1:-1]]\n",
    "            for i in xrange(ratings.shape[0]):\n",
    "                pred[i, j] = similarity[j, :][top_k_items].dot(ratings[i, :][top_k_items].T) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[j, :][top_k_items]))        \n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_pred_nocorrec_topk2 = predict_nocorrec_topk(np.array(train_data2), np.array(user_similarity2), kind='user', k=40)\n",
    "item_pred_nocorrec_topk2 = predict_nocorrec_topk(np.array(train_data2), np.array(item_similarity2), kind='item', k=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "without correction for user-item\n",
      "Top-k User-based CF MSE: 6.37583556979\n",
      "Top-k Item-based CF MSE: 7.60263542522\n"
     ]
    }
   ],
   "source": [
    "print \"without correction for user-item\"\n",
    "print 'Top-k User-based CF MSE: ' + str(mse(user_pred_nocorrec_topk2, np.array(test_data2)))\n",
    "print 'Top-k Item-based CF MSE: ' + str(mse(item_pred_nocorrec_topk2, np.array(test_data2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can try tuning the parameter of *k* to find the optimal value for minimizing our testing MSE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Validation \n",
    "\n",
    "    we can look at item similarity matrix and see if similar items do make sense in reality ( compare to google's recomendation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# real movie index\n",
    "new_movie_index\n",
    "inver_new_movie_index = dict((v,k) for k,v in new_movie_index.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_k_movies(similarity, index_to_title , movie_idx, k=6):\n",
    "    return [index_to_title[x] for x in np.argsort(similarity[movie_idx,:])[:-k-1:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   [**Pulp Fiction (1994)**](https://en.wikipedia.org/wiki/Pulp_Fiction)\n",
    "\n",
    "   - Top 5 from Google search:\n",
    "       \n",
    "           Reservoir Dogs \n",
    "           Jackie Brown\n",
    "           True Romance\n",
    "           Kill Bill: volume 1\n",
    "           American Ganster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pulp Fiction (1994)',\n",
       " 'Afterglow (1997)',\n",
       " 'French Kiss (1995)',\n",
       " 'Raiders of the Lost Ark (1981)',\n",
       " 'Mars Attacks! (1996)',\n",
       " 'Star Wars (1977)',\n",
       " 'In the Name of the Father (1993)',\n",
       " 'Wizard of Oz, The (1939)',\n",
       " \"Devil's Own, The (1997)\",\n",
       " 'Dave (1993)',\n",
       " 'Chasing Amy (1997)']"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Pulp Fiction (1994)\" in new_movie_index\n",
    "print new_movie_index[\"Pulp Fiction (1994)\"]\n",
    "top_k_movies(np.array(item_similarity1), inver_new_movie_index, 217, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Pulp Fiction (1994)',\n",
       " 'Silence of the Lambs, The (1991)',\n",
       " 'Raiders of the Lost Ark (1981)',\n",
       " 'Fugitive, The (1993)',\n",
       " 'Back to the Future (1985)',\n",
       " 'Forrest Gump (1994)',\n",
       " 'Usual Suspects, The (1995)',\n",
       " 'Terminator 2: Judgment Day (1991)',\n",
       " 'Terminator, The (1984)',\n",
       " 'Empire Strikes Back, The (1980)',\n",
       " 'Monty Python and the Holy Grail (1974)']"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Pulp Fiction (1994)\" in new_movie_index\n",
    "print new_movie_index[\"Pulp Fiction (1994)\"]\n",
    "top_k_movies(np.array(item_similarity2), inver_new_movie_index, 217, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [**Reservoir Dogs (1992)**](https://www.google.com/search?client=safari&sa=X&rls=en&q=Reservoir+Dogs&stick=H4sIAAAAAAAAAONgFuLQz9U3SDOJz1HiArGMMkzMTC20pLKTrfTTMnNywYRVUWpOYklqikJxakkxAMfU_fk0AAAA&ved=0ahUKEwikkpP5vIXZAhVK0lMKHaUjByUQxA0IjwMwJw&biw=1280&bih=739)\n",
    "   \n",
    "\n",
    "   - Top 5 from Google search:\n",
    "       \n",
    "           Pulp Fiction \n",
    "           True Romance\n",
    "           The Usual Suspect\n",
    "           Jackie Brown\n",
    "           Heat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Reservoir Dogs (1992)',\n",
       " 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)',\n",
       " 'Home for the Holidays (1995)',\n",
       " 'Full Monty, The (1997)',\n",
       " 'Trees Lounge (1996)',\n",
       " 'In & Out (1997)',\n",
       " 'Fallen (1998)',\n",
       " 'Fools Rush In (1997)',\n",
       " 'Stealing Beauty (1996)',\n",
       " 'Once Upon a Time... When We Were Colored (1995)',\n",
       " 'Michael Collins (1996)']"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Reservoir Dogs (1992)\" in new_movie_index\n",
    "print new_movie_index[\"Reservoir Dogs (1992)\"]\n",
    "top_k_movies(np.array(item_similarity1), inver_new_movie_index, 351, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Reservoir Dogs (1992)',\n",
       " 'Usual Suspects, The (1995)',\n",
       " 'Pulp Fiction (1994)',\n",
       " 'Blade Runner (1982)',\n",
       " 'Full Metal Jacket (1987)',\n",
       " 'Alien (1979)',\n",
       " 'Die Hard (1988)',\n",
       " 'Seven (Se7en) (1995)',\n",
       " 'Aliens (1986)',\n",
       " 'Twelve Monkeys (1995)',\n",
       " 'Fugitive, The (1993)']"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Reservoir Dogs (1992)\" in new_movie_index\n",
    "print new_movie_index[\"Reservoir Dogs (1992)\"]\n",
    "top_k_movies(np.array(item_similarity2), inver_new_movie_index, 351, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to say if the recommender do a great job or not since the movies are all quite old. However, we can notice that using second way to split the data provide more reasonable result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
